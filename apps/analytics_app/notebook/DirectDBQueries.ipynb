{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2161b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "\n",
    "    return conn[db]\n",
    "\n",
    "db = _connect_mongo(host='localhost', port=27017, username=None, password=None, db='OpenRoadDB')\n",
    "\n",
    "KPI = db.kpi\n",
    "ENGINE = db.engine_history\n",
    "\n",
    "output_path = '/Users/rajiv/Development/iora/python/openroad/ride_hailing/apps/output'\n",
    "\n",
    "\n",
    "# run_id_meta = {\n",
    "#     # # 'FIQgwybgpIv6': 'Random old',\n",
    "#     # # '8X6m0Rkz5G1W': 'Greedy Pickup old',\n",
    "#     # # '6roQmPCm6O9N': 'Greedy Revenue old',\n",
    "#     # # 'w67ZLPpg4V27': 'Greedy Service old',\n",
    "#     # '': 'Random 2',\n",
    "#     # '': 'Greedy Pickup 2',\n",
    "#     # '': 'Greedy Revenue 2',\n",
    "#     '5IORM3YrHlwR': 'Greedy Service 2',\n",
    "# #     '': 'Compromise',\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66399b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, tzinfo, timezone\n",
    "from pymongo.cursor import CursorType\n",
    "\n",
    "\n",
    "def get_paths_from_cursor(collection, args, filter):\n",
    "\n",
    "    # print(args)\n",
    "    _from = args.get('from')\n",
    "    from_dt = datetime.strptime(_from, '%Y%m%d%H%M%S').replace(tzinfo=timezone.utc)\n",
    "    _to = args.get('to')\n",
    "    to_dt = datetime.strptime(_to, '%Y%m%d%H%M%S').replace(tzinfo=timezone.utc)\n",
    "\n",
    "    filter[\"sim_clock\"] = {\n",
    "        \"$gte\": from_dt,\n",
    "        \"$lt\": to_dt\n",
    "    }\n",
    "    # print(filter)\n",
    "    project = {\n",
    "        '_id': 0,\n",
    "        \"event.state\": 1,\n",
    "        \"event.location.coordinates\": 1,\n",
    "        \"event.traversed_path\": 1,\n",
    "        \"trip\": 1,\n",
    "        \"sim_clock\": 1,\n",
    "    }\n",
    "    sort=list({\n",
    "        'trip': 1,\n",
    "        'counter': 1\n",
    "    }.items())\n",
    "\n",
    "    cursor = collection.find(\n",
    "        filter=filter,\n",
    "        projection=project,\n",
    "        sort=sort,\n",
    "        cursor_type=CursorType.EXHAUST\n",
    "    )\n",
    "\n",
    "    trip = {\n",
    "        'trip_id': None,\n",
    "        'tripclass': None,\n",
    "        'path': [],\n",
    "        'traversed_path': [],\n",
    "        'timestamps': [],\n",
    "    }\n",
    "    paths = []\n",
    "    for document in cursor:\n",
    "        trip_id = str(document['trip'])\n",
    "        coord = [round(x, 5) for x in document['event']['location']['coordinates']]\n",
    "        traversed_path = document['event'].get('traversed_path') \\\n",
    "                            if document['event'].get('traversed_path') is not None \\\n",
    "                            else []\n",
    "        tripclass = document['event']['state']\n",
    "        ts = document['sim_clock'].replace(tzinfo=timezone.utc)\n",
    "\n",
    "        if trip['trip_id'] is None:\n",
    "            trip = {\n",
    "                'trip_id': trip_id,\n",
    "                'tripclass': tripclass,\n",
    "                'path': [coord],\n",
    "                'traversed_path': traversed_path,\n",
    "                'timestamps': [(ts-from_dt).seconds],\n",
    "            }\n",
    "        elif (trip['trip_id'] == trip_id) and (trip['tripclass'] == tripclass):\n",
    "            trip['path'].append(coord)\n",
    "            trip['traversed_path'].extend(traversed_path)\n",
    "            trip['timestamps'].append((ts-from_dt).seconds)\n",
    "        else:\n",
    "            if len(trip['path']) > 1:\n",
    "                paths.append(trip)\n",
    "            trip = {\n",
    "                'trip_id': trip_id,\n",
    "                'tripclass': tripclass,\n",
    "                'path': [coord],\n",
    "                'traversed_path': traversed_path,\n",
    "                'timestamps': [(ts-from_dt).seconds],\n",
    "            }\n",
    "\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25f9eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "WAYPOINT = db.waypoint\n",
    "\n",
    "filter = {\n",
    "    'run_id': 'iWuf33bxKkzv',\n",
    "}\n",
    "\n",
    "for t in range(8, 16):\n",
    "    args = {\n",
    "        'from': f\"20200101{t:02}0000\",\n",
    "        'to': f\"20200101{t+1:02}0000\"\n",
    "    }\n",
    "\n",
    "    paths = get_paths_from_cursor(WAYPOINT, args, filter)\n",
    "\n",
    "    with open(f\"{output_path}/{filter['run_id']}/paths_{args['from']}_{args['to']}.json\", 'w') as file:\n",
    "        json.dump(paths, file, indent=2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc575bbf-1b7b-4cff-8dfa-44a1d4e6cdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974773a6-f6a7-483a-99dd-e914d451f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot(collection, run_id_meta, metric):\n",
    "    cursor = collection.find({\n",
    "            'run_id': {'$in': [k for k, _ in run_id_meta.items()]},\n",
    "            'metric': metric\n",
    "        },\n",
    "        projection={ '_id': 0, 'run_id': 1, 'sim_clock': 1, 'value': 1,},\n",
    "        sort=[('sim_clock', 1)]\n",
    "    )\n",
    "\n",
    "    metric_df = pd.DataFrame(list(cursor))\n",
    "\n",
    "    metric_pivot = pd.pivot_table(metric_df, \n",
    "                                  index='sim_clock', \n",
    "                                  columns='run_id', \n",
    "                                  values='value').rename(columns=run_id_meta)\n",
    "    cumulative_pivot = metric_pivot.cumsum()\n",
    "\n",
    "    return metric_pivot, cumulative_pivot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737c0640-62ab-457a-b5f7-2f7f50be65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KPI = db.kpi\n",
    "\n",
    "sum_metric = [\n",
    "    'served', \n",
    "    'cancelled',\n",
    "    'revenue', \n",
    "    'wait_time_pickup',\n",
    "    'service_score'\n",
    "]\n",
    "avg_metric_byServed = [\n",
    "    'revenue',\n",
    "    'wait_time_pickup',\n",
    "    'service_score',\n",
    "]\n",
    "# avg_metric_byAccepted = [\n",
    "#     'service_score'\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f8b099-83ac-460e-ac09-72c057f1dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_id_meta = {\n",
    "    filter['run_id']: 'value',\n",
    "}\n",
    "for m in sum_metric:\n",
    "    metric_pivot, cum_pivot = get_pivot(KPI, run_id_meta, m)\n",
    "    cum_pivot['sim_clock'] = metric_pivot.index\n",
    "\n",
    "    metrics = cum_pivot.to_dict(orient='records')\n",
    "\n",
    "    with open (f\"{output_path}/{filter['run_id']}/plot_cumulative_{m}.json\", 'w') as file:\n",
    "        json.dump(metrics, file, default=str, indent=2)\n",
    "\n",
    "served_pivot, served_cum_pivot = get_pivot(KPI, run_id_meta, 'served')\n",
    "for m in avg_metric_byServed:\n",
    "    metric_pivot, cum_pivot = get_pivot(KPI, run_id_meta, m)\n",
    "    metric_pivot = metric_pivot / served_pivot\n",
    "    cum_pivot = cum_pivot / served_cum_pivot\n",
    "    \n",
    "    metric_pivot['sim_clock'] = metric_pivot.index \n",
    "    cum_pivot['sim_clock'] = cum_pivot.index\n",
    "\n",
    "    metrics = cum_pivot.to_dict(orient='records')\n",
    "\n",
    "    with open (f\"{output_path}/{filter['run_id']}/plot_avg_{m}_by_served.json\", 'w') as file:\n",
    "        json.dump(metrics, file, default=str, indent=2)\n",
    "\n",
    "        \n",
    "\n",
    "# num_accepted_pivot = get_cumulative_pivot(KPI, run_id_meta, 'num_accepted')\n",
    "# for m in avg_metric_byAccepted:\n",
    "#     metric_pivot = get_cumulative_pivot(KPI, run_id_meta, m) / num_accepted_pivot\n",
    "#     metric_pivot['sim_clock'] = metric_pivot.index\n",
    "\n",
    "#     metrics = metric_pivot.to_dict(orient='records')\n",
    "\n",
    "#     with open (f\"plot_avg_{m}_by_accepted.json\", 'w') as file:\n",
    "#         json.dump(metrics, file, default=str, indent=2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca1680-7b4b-46f6-93f6-a440842a6287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be8851-96c9-4e89-aee3-cc6ebecee2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
